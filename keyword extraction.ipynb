{"cells":[{"cell_type":"markdown","metadata":{"id":"Ah69j6JCkD0d"},"source":["# Universal imports"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lF9itqGPj8TG"},"outputs":[],"source":["from google.colab import drive\n","import pandas as pd"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16958,"status":"ok","timestamp":1693991913868,"user":{"displayName":"Leo Krohne","userId":"06951649563844802184"},"user_tz":-120},"id":"edMFYnv0j243","outputId":"528d719e-7640-43a3-8450-518eccbfc1b5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["# Import BERT-ready data from Gdrive\n","drive.mount('/content/gdrive')"]},{"cell_type":"markdown","source":["# Clone git repo"],"metadata":{"id":"Fd8bYCTMrU-w"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3467,"status":"ok","timestamp":1693990268689,"user":{"displayName":"Leo Krohne","userId":"06951649563844802184"},"user_tz":-120},"id":"OSCTRAV0uGye","outputId":"3a228f5c-3cdc-4180-f7a8-446ddd6ca9fb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'ss23-drop-in-to-berlin'...\n","remote: Enumerating objects: 281, done.\u001b[K\n","remote: Counting objects: 100% (43/43), done.\u001b[K\n","remote: Compressing objects: 100% (22/22), done.\u001b[K\n","remote: Total 281 (delta 21), reused 25 (delta 21), pack-reused 238\u001b[K\n","Receiving objects: 100% (281/281), 6.51 MiB | 4.82 MiB/s, done.\n","Resolving deltas: 100% (143/143), done.\n"]}],"source":["!git clone https://{git_token}@github.com/{username}/{repository}"]},{"cell_type":"markdown","source":["# other git stuff"],"metadata":{"id":"EsVYdc2eyZA4"}},{"cell_type":"code","execution_count":52,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1693994659660,"user":{"displayName":"Leo Krohne","userId":"06951649563844802184"},"user_tz":-120},"id":"4K_DGfv4u7KI"},"outputs":[],"source":["username = \"TechLabs-Berlin\"\n","repository = \"ss23-drop-in-to-berlin\"\n","git_token = \"\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1693991980417,"user":{"displayName":"Leo Krohne","userId":"06951649563844802184"},"user_tz":-120},"id":"LRuVAmr3uBDB","outputId":"22ba2645-bb60-4b1f-a1aa-d34b4103e5b4"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/TechLabs/ss23-drop-in-to-berlin\n"]}],"source":["cd /content/gdrive/MyDrive/TechLabs/{repository}"]},{"cell_type":"code","source":["pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"hIHrbE2UycjX","executionInfo":{"status":"ok","timestamp":1693991949993,"user_tz":-120,"elapsed":5,"user":{"displayName":"Leo Krohne","userId":"06951649563844802184"}},"outputId":"4f2d4c68-9e2a-40a5-a7d5-3d819a30a749"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/gdrive/MyDrive/TechLabs'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["!git branch recommender main"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R0tnaH7KywRz","executionInfo":{"status":"ok","timestamp":1693992184318,"user_tz":-120,"elapsed":294,"user":{"displayName":"Leo Krohne","userId":"06951649563844802184"}},"outputId":"c67dab7d-3bcd-4ba6-c110-e82ebee375ef"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: A branch named 'recommender' already exists.\n"]}]},{"cell_type":"code","source":["!git checkout recommender"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xam7-2Aj0NfI","executionInfo":{"status":"ok","timestamp":1693992666438,"user_tz":-120,"elapsed":336,"user":{"displayName":"Leo Krohne","userId":"06951649563844802184"}},"outputId":"61d98df7-bbb9-4faa-d2fe-b72ec703da28"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Switched to branch 'recommender'\n","Your branch is up to date with 'origin/recommender'.\n"]}]},{"cell_type":"code","source":["!git branch"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YZhhZ4CI2Dse","executionInfo":{"status":"ok","timestamp":1693992896390,"user_tz":-120,"elapsed":619,"user":{"displayName":"Leo Krohne","userId":"06951649563844802184"}},"outputId":"37f7f1f0-7fc4-4310-ba7f-e2555166ef5b"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["  main\u001b[m\n","* \u001b[32mrecommender\u001b[m\n"]}]},{"cell_type":"code","source":["!git config --global user.email \"phylanx@gmx.de\"\n","!git config --global user.name \"phylanxy\""],"metadata":{"id":"ODNw4-20y8SO","executionInfo":{"status":"ok","timestamp":1693993464708,"user_tz":-120,"elapsed":249,"user":{"displayName":"Leo Krohne","userId":"06951649563844802184"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":["!git add ."],"metadata":{"id":"znsU4TnjyJMN","executionInfo":{"status":"ok","timestamp":1693993212823,"user_tz":-120,"elapsed":1506,"user":{"displayName":"Leo Krohne","userId":"06951649563844802184"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["!git commit -m \"combined keyBERTopic extraction\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p3xEic_WynAA","executionInfo":{"status":"ok","timestamp":1693993214107,"user_tz":-120,"elapsed":381,"user":{"displayName":"Leo Krohne","userId":"06951649563844802184"}},"outputId":"8b601779-5901-4593-aea5-a4deecd6ef24"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["[recommender a922225] combined keyBERTopic extraction\n"," 2 files changed, 2 insertions(+), 1 deletion(-)\n"," create mode 100644 combined keyBERTopic extraction.ipynb\n"," rewrite keyword extraction.ipynb (91%)\n"]}]},{"cell_type":"code","source":["!git push"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wDLWaFqn0PRU","executionInfo":{"status":"ok","timestamp":1693994672544,"user_tz":-120,"elapsed":632,"user":{"displayName":"Leo Krohne","userId":"06951649563844802184"}},"outputId":"d1290658-3577-4033-c18f-39625e52e60b"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: could not read Password for 'https://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@github.com': No such device or address\n"]}]},{"cell_type":"markdown","metadata":{"id":"ZNKPbcPLe-87"},"source":["# Installing requierd packages for keyword extraction\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9WnK02q6ALyw","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1693929286488,"user_tz":-120,"elapsed":32768,"user":{"displayName":"Otto Kraus","userId":"09313844023429711923"}},"outputId":"7c8deb5f-765e-47c4-8680-07568777b089"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.33.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Collecting keybert\n","  Downloading keybert-0.7.0.tar.gz (21 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: sentence-transformers>=0.3.8 in /usr/local/lib/python3.10/dist-packages (from keybert) (2.2.2)\n","Requirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.10/dist-packages (from keybert) (1.2.2)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from keybert) (1.23.5)\n","Requirement already satisfied: rich>=10.4.0 in /usr/local/lib/python3.10/dist-packages (from keybert) (13.5.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.4.0->keybert) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.4.0->keybert) (2.16.1)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2->keybert) (1.10.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2->keybert) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2->keybert) (3.2.0)\n","Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.3.8->keybert) (4.33.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.3.8->keybert) (4.66.1)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.3.8->keybert) (2.0.1+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.3.8->keybert) (0.15.2+cu118)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.3.8->keybert) (3.8.1)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.3.8->keybert) (0.1.99)\n","Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.3.8->keybert) (0.16.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (3.12.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (2023.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (2.31.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (6.0.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (4.7.1)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (23.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.4.0->keybert) (0.1.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers>=0.3.8->keybert) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers>=0.3.8->keybert) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers>=0.3.8->keybert) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers>=0.3.8->keybert) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers>=0.3.8->keybert) (3.27.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers>=0.3.8->keybert) (16.0.6)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (2023.6.3)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (0.13.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (0.3.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers>=0.3.8->keybert) (8.1.7)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers>=0.3.8->keybert) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers>=0.3.8->keybert) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (2023.7.22)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers>=0.3.8->keybert) (1.3.0)\n","Building wheels for collected packages: keybert\n","  Building wheel for keybert (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keybert: filename=keybert-0.7.0-py3-none-any.whl size=23765 sha256=7ae12d73a556258a9a37d8e4d5c161baa87c041a25049437bc92469e46a7631b\n","  Stored in directory: /root/.cache/pip/wheels/66/8d/e6/b0e2f8d883b0fd51819226f67ad9843e04913ce4a97241ff4b\n","Successfully built keybert\n","Installing collected packages: keybert\n","Successfully installed keybert-0.7.0\n","Collecting keyphrase-vectorizers\n","  Downloading keyphrase_vectorizers-0.0.11-py3-none-any.whl (29 kB)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from keyphrase-vectorizers) (1.23.5)\n","Requirement already satisfied: spacy>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from keyphrase-vectorizers) (3.6.1)\n","Collecting spacy-transformers>=1.1.6 (from keyphrase-vectorizers)\n","  Downloading spacy_transformers-1.2.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (190 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.8/190.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: nltk>=3.6.1 in /usr/local/lib/python3.10/dist-packages (from keyphrase-vectorizers) (3.8.1)\n","Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.10/dist-packages (from keyphrase-vectorizers) (1.2.2)\n","Requirement already satisfied: scipy>=1.7.3 in /usr/local/lib/python3.10/dist-packages (from keyphrase-vectorizers) (1.10.1)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from keyphrase-vectorizers) (5.9.5)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.6.1->keyphrase-vectorizers) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.6.1->keyphrase-vectorizers) (1.3.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.6.1->keyphrase-vectorizers) (2023.6.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.6.1->keyphrase-vectorizers) (4.66.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->keyphrase-vectorizers) (3.2.0)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->keyphrase-vectorizers) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->keyphrase-vectorizers) (1.0.4)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->keyphrase-vectorizers) (1.0.9)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->keyphrase-vectorizers) (2.0.7)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->keyphrase-vectorizers) (3.0.8)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->keyphrase-vectorizers) (8.1.12)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->keyphrase-vectorizers) (1.1.2)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->keyphrase-vectorizers) (2.4.7)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->keyphrase-vectorizers) (2.0.9)\n","Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->keyphrase-vectorizers) (0.9.0)\n","Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->keyphrase-vectorizers) (0.10.2)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->keyphrase-vectorizers) (6.3.0)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->keyphrase-vectorizers) (2.31.0)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->keyphrase-vectorizers) (2.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->keyphrase-vectorizers) (3.1.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->keyphrase-vectorizers) (67.7.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->keyphrase-vectorizers) (23.1)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->keyphrase-vectorizers) (3.3.0)\n","Collecting transformers<4.31.0,>=3.4.0 (from spacy-transformers>=1.1.6->keyphrase-vectorizers)\n","  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from spacy-transformers>=1.1.6->keyphrase-vectorizers) (2.0.1+cu118)\n","Collecting spacy-alignments<1.0.0,>=0.7.2 (from spacy-transformers>=1.1.6->keyphrase-vectorizers)\n","  Downloading spacy_alignments-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.0.1->keyphrase-vectorizers) (0.5.0)\n","Requirement already satisfied: pydantic-core==2.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.0.1->keyphrase-vectorizers) (2.6.1)\n","Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.0.1->keyphrase-vectorizers) (4.7.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.1->keyphrase-vectorizers) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.1->keyphrase-vectorizers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.1->keyphrase-vectorizers) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.1->keyphrase-vectorizers) (2023.7.22)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy>=3.0.1->keyphrase-vectorizers) (0.7.10)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy>=3.0.1->keyphrase-vectorizers) (0.1.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (3.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (3.1)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (3.27.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (16.0.6)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers<4.31.0,>=3.4.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (0.16.4)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers<4.31.0,>=3.4.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (6.0.1)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers<4.31.0,>=3.4.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (0.13.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<4.31.0,>=3.4.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (0.3.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy>=3.0.1->keyphrase-vectorizers) (2.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers<4.31.0,>=3.4.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (2023.6.0)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (1.3.0)\n","Installing collected packages: spacy-alignments, transformers, spacy-transformers, keyphrase-vectorizers\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.33.0\n","    Uninstalling transformers-4.33.0:\n","      Successfully uninstalled transformers-4.33.0\n","Successfully installed keyphrase-vectorizers-0.0.11 spacy-alignments-0.9.0 spacy-transformers-1.2.5 transformers-4.30.2\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["transformers"]}}},"metadata":{}}],"source":["!pip install transformers\n","!pip install keybert\n","!pip install keyphrase-vectorizers"]},{"cell_type":"markdown","metadata":{"id":"rhXcewoxfM3-"},"source":["# Importing libraries for keyword extraction"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pLSk0n6tw6zN"},"outputs":[],"source":["from keybert import KeyBERT\n","from keyphrase_vectorizers import KeyphraseCountVectorizer"]},{"cell_type":"markdown","metadata":{"id":"rykJUhVPfUF3"},"source":["# Loading the data & data cleaning\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t_Q4DvtAbvH1"},"outputs":[],"source":["df = pd.read_csv(\"/content/gdrive/MyDrive/Ironhack/Final_project/df_with_model_input_no_NaNs.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vhD0_XAob-RA"},"outputs":[],"source":["# function to remove items specified in a list\n","def preprocess_input(string, lst_to_remove):\n","  for item in lst_to_remove:\n","    string = string.replace(item, \"\")\n","  if len(string.split()) < 4:\n","    string = None\n","  else:\n","    pass\n","  return string\n","\n","# create a list to remove strings that don't carry meaning\n","remove_lst = [\"'review0': \",\"'review1': \",\"'review2': \",\"'review3': \",\"'review4': \", \"'editorial_summary':\", \"restaurant\", \"place\", \"dinner\", \"berlin\", \"berlino\", \"berlins\"]"]},{"cell_type":"code","source":["# drop old indeces\n","df.drop([\"Unnamed: 0\", \"Unnamed: 0.1\"], inplace=True, axis=1)"],"metadata":{"id":"e0iJNYq7EIXW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# turn model input into the review text without the items specified in remove_lst\n","df[\"model_input\"] = df[\"model_input\"].apply(lambda x: preprocess_input(str(x), remove_lst) if x != None else \"\")"],"metadata":{"id":"KPnzyqnU8Ycm"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Akax3lZ0cCrN"},"outputs":[],"source":["# convert everything into str, add empty string for anything that's not a string (keyBERT won't accept NaNs as input, but I want to preserve the order of the inputs, for correct assignemetn of the outputs to the corresponding rows)\n","# and then create a list of texts for keyBERT to process\n","BERTs = df[\"model_input\"]"]},{"cell_type":"markdown","metadata":{"id":"kHHdMrdoffUU"},"source":["# Build keyBERT model and extract the keywords"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jB7KohKTYofo"},"outputs":[],"source":["# Load a pre-trained BERT model for keyword extraction\n","kw_model = KeyBERT(model=\"all-MiniLM-L6-v2\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ykiW2GNd1ZVS"},"outputs":[],"source":["# Input document\n","document = BERTs\n","\n","# initialize vectorizer with customized options for extracting zero or one adjective plus one or more nouns\n","vectorizer = KeyphraseCountVectorizer(pos_pattern='<J.*>{0,1}<N.*>+', stop_words=\"english\")\n","\n","# Extract keywords using KeyBERT\n","keywords = kw_model.extract_keywords(document, vectorizer=vectorizer, top_n=6)\n","\n","# Print the top keywords\n","keywords"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aJ1OQjXmRd7H"},"outputs":[],"source":["# function that returns only keywords without probabilities\n","def tpls_to_lst(tpls):\n","  keywords_lst = []\n","  for sublist in tpls:\n","    word_lst = [word[0] for word in sublist]\n","    keywords_lst.append(word_lst)\n","  return keywords_lst"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-gyYjEWab3YY"},"outputs":[],"source":["# extract words from touples\n","keywords_lst = tpls_to_lst(keywords)\n","keywords_lst"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yph-iir6rsQI"},"outputs":[],"source":["# build a dataframe from the keywords and store it in gdrive as a csv file\n","keywords_df = pd.DataFrame(keywords_lst)"]},{"cell_type":"code","source":["# save to keywords.csv if needed\n","keywords_df.to_csv(\"/content/gdrive/MyDrive/Techlabs/keywords.csv\", index_label=None)"],"metadata":{"id":"tu0PMlSkFbw7"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LtSEDpQnU4pl"},"outputs":[],"source":["# try keyword extraction for possible user input\n","user_input = \"I want a restaurant that is beautiful and where the waiters are very friendly, the desserts are delicious and I can bring my dog.\".replace(\"restaurant\", \"\")\n","\n","# Extract keywords using KeyBERT\n","user_keywords = kw_model.extract_keywords(user_input, vectorizer=vectorizer, top_n=6)\n","\n","user_keywords"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7Vn0F-vDda0q"},"outputs":[],"source":["keywords_lst"]},{"cell_type":"markdown","metadata":{"id":"0vU7fWG3jx4P"},"source":["# Clustering keywords into topics\n","## load data\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5JJFNFbi76i5"},"outputs":[],"source":["# load keywords from csv\n","keywords_df = pd.read_csv(\"/content/gdrive/MyDrive/Techlabs/keywords.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DLer_SkHwpos"},"outputs":[],"source":["# get all unique keywords and save in keywords_lst\n","keywords_lst = list(set([item for sublist in keywords_df.applymap(str).values.tolist() for item in sublist]))\n","keywords_lst"]},{"cell_type":"markdown","metadata":{"id":"wI3nKy2JBhYm"},"source":["## BERTopic approach"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GF54MnRIysLf"},"outputs":[],"source":["!pip install --upgrade numpy numba"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M6nAzyCggzm2"},"outputs":[],"source":["!pip install bertopic"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DLQF07_9xV5B"},"outputs":[],"source":["from bertopic import BERTopic\n","from bertopic.representation import MaximalMarginalRelevance\n","from sentence_transformers import SentenceTransformer\n","from transformers import pipeline\n","from bertopic.representation import KeyBERTInspired\n","from hdbscan import HDBSCAN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gpz4LkKAj3fr"},"outputs":[],"source":["#0 create embeddings by using a pipeline as a high-level helper\n","embedding_model = pipeline(\"feature-extraction\", model=\"vocab-transformers/distilbert-word2vec_256k-MLM_best\")\n","\n","#1 customize clustering model\n","hdbscan_model = HDBSCAN(min_cluster_size=10, metric='euclidean', cluster_selection_method='eom', prediction_data=True)\n","\n","#2 use keyBERT to define topic labels\n","representation_model = KeyBERTInspired()\n","\n","#3 built topic model and fit on the keywords\n","topic_model = BERTopic(embedding_model=embedding_model, hdbscan_model=hdbscan_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TjeHCcH25jSY"},"outputs":[],"source":["#4 fit & transform\n","docs = keywords_lst\n","topics, probs = topic_model.fit_transform(docs)"]},{"cell_type":"code","source":["from joblib import dump, load\n","\n","# save model in a joblib file (safer than pickle)\n","dump(topic_model, '/content/gdrive/MyDrive/Techlabs/keyBERT_model_word2vec_eom_GPU.joblib')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gvx1WGufLuag","executionInfo":{"status":"ok","timestamp":1693931662478,"user_tz":-120,"elapsed":37260,"user":{"displayName":"Otto Kraus","userId":"09313844023429711923"}},"outputId":"213ef1a3-0bc2-4ea9-db7f-bafacbbdae33"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['/content/gdrive/MyDrive/Techlabs/keyBERT_model_word2vec_eom_GPU.joblib']"]},"metadata":{},"execution_count":123}]},{"cell_type":"markdown","metadata":{"id":"hwEaeyl0myEZ"},"source":["### visualize resulting topics"]},{"cell_type":"code","source":["from sklearn.datasets import fetch_20newsgroups\n","from bertopic import BERTopic\n","from wordcloud import WordCloud\n","import matplotlib.pyplot as plt"],"metadata":{"id":"qpez_k_eqsiS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create wordcloud for each topic\n","def create_wordcloud(topic_model, topic):\n","    text = {word: value for word, value in topic_model.get_topic(topic)}\n","    wc = WordCloud(background_color=\"white\", max_words=1000)\n","    wc.generate_from_frequencies(text)\n","    plt.imshow(wc, interpolation=\"bilinear\")\n","    plt.axis(\"off\")\n","    plt.show()\n","\n","# Show word cloud\n","for topic in topic_model.get_topic_info()[\"Topic\"]:\n","  create_wordcloud(topic_model, topic=topic)"],"metadata":{"id":"0N5KxRxaqDhA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["candidates = [\"vegetarian\", \"sushi\", \"ramen\", \"dessert\", ]"],"metadata":{"id":"iimZRYGhk9cK"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l9lGrvpYwOon"},"outputs":[],"source":["topic_model.get_topic(1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":427,"status":"ok","timestamp":1693931573291,"user":{"displayName":"Otto Kraus","userId":"09313844023429711923"},"user_tz":-120},"id":"z-lHqN2knWLN","outputId":"6d1e5298-9cc7-463d-f8b3-c00c5b5ab6c0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["     Topic  Count                                       Name  \\\n","0       -1   2843             -1_pizza_best_pizzas_authentic   \n","1        0    250               0_spandau_potsdam_gate_platz   \n","2        1    169              1_sushi_sushis_nigiri_tempura   \n","3        2    161           2_schwarma_makali_lietzensee_nem   \n","4        3    147               3_burger_burgers_cheese_king   \n","..     ...    ...                                        ...   \n","177    176     10          176_wines_wine_serbian_macedonian   \n","178    177     10         177_station_bahn_train_gesunbrunen   \n","179    178     10  178_thuringian_blau_schwabischen_schiller   \n","180    179     10  179_training_employees_trainees_operation   \n","181    180     10            180_brilliant_ok_pizza_mediocre   \n","\n","                                        Representation  \\\n","0    [pizza, best, pizzas, authentic, style, food, ...   \n","1    [spandau, potsdam, gate, platz, rathaus, kaise...   \n","2    [sushi, sushis, nigiri, tempura, rolls, top, p...   \n","3    [schwarma, makali, lietzensee, nem, kibbeh, ku...   \n","4    [burger, burgers, cheese, king, cheeseburger, ...   \n","..                                                 ...   \n","177  [wines, wine, serbian, macedonian, croatian, i...   \n","178  [station, bahn, train, gesunbrunen, weg, sudkr...   \n","179  [thuringian, blau, schwabischen, schiller, obe...   \n","180  [training, employees, trainees, operation, job...   \n","181  [brilliant, ok, pizza, mediocre, poor, takeawa...   \n","\n","                                   Representative_Docs  \n","0    [best chicken burger, good quality pizzas, coz...  \n","1    [brandenburger gate, rathaus spandau, brandenb...  \n","2                      [good sushi, best sushi, sushi]  \n","3    [great schwarma, schwarma, tasty chicken schwa...  \n","4           [delicious burger, burger, chicken burger]  \n","..                                                 ...  \n","177         [german wines, greek wines, italian wines]  \n","178  [ostkreuz train station, picturesque nikolasse...  \n","179  [kaffee crema, thuringian bread, thuringian br...  \n","180    [other employees, training operation, training]  \n","181        [mediocre pizza, ok pizza, brilliant pizza]  \n","\n","[182 rows x 5 columns]"],"text/html":["\n","  <div id=\"df-d30ce895-80d7-4cdd-9a18-ef2961c3dd49\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Topic</th>\n","      <th>Count</th>\n","      <th>Name</th>\n","      <th>Representation</th>\n","      <th>Representative_Docs</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-1</td>\n","      <td>2843</td>\n","      <td>-1_pizza_best_pizzas_authentic</td>\n","      <td>[pizza, best, pizzas, authentic, style, food, ...</td>\n","      <td>[best chicken burger, good quality pizzas, coz...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>250</td>\n","      <td>0_spandau_potsdam_gate_platz</td>\n","      <td>[spandau, potsdam, gate, platz, rathaus, kaise...</td>\n","      <td>[brandenburger gate, rathaus spandau, brandenb...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>169</td>\n","      <td>1_sushi_sushis_nigiri_tempura</td>\n","      <td>[sushi, sushis, nigiri, tempura, rolls, top, p...</td>\n","      <td>[good sushi, best sushi, sushi]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2</td>\n","      <td>161</td>\n","      <td>2_schwarma_makali_lietzensee_nem</td>\n","      <td>[schwarma, makali, lietzensee, nem, kibbeh, ku...</td>\n","      <td>[great schwarma, schwarma, tasty chicken schwa...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>3</td>\n","      <td>147</td>\n","      <td>3_burger_burgers_cheese_king</td>\n","      <td>[burger, burgers, cheese, king, cheeseburger, ...</td>\n","      <td>[delicious burger, burger, chicken burger]</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>177</th>\n","      <td>176</td>\n","      <td>10</td>\n","      <td>176_wines_wine_serbian_macedonian</td>\n","      <td>[wines, wine, serbian, macedonian, croatian, i...</td>\n","      <td>[german wines, greek wines, italian wines]</td>\n","    </tr>\n","    <tr>\n","      <th>178</th>\n","      <td>177</td>\n","      <td>10</td>\n","      <td>177_station_bahn_train_gesunbrunen</td>\n","      <td>[station, bahn, train, gesunbrunen, weg, sudkr...</td>\n","      <td>[ostkreuz train station, picturesque nikolasse...</td>\n","    </tr>\n","    <tr>\n","      <th>179</th>\n","      <td>178</td>\n","      <td>10</td>\n","      <td>178_thuringian_blau_schwabischen_schiller</td>\n","      <td>[thuringian, blau, schwabischen, schiller, obe...</td>\n","      <td>[kaffee crema, thuringian bread, thuringian br...</td>\n","    </tr>\n","    <tr>\n","      <th>180</th>\n","      <td>179</td>\n","      <td>10</td>\n","      <td>179_training_employees_trainees_operation</td>\n","      <td>[training, employees, trainees, operation, job...</td>\n","      <td>[other employees, training operation, training]</td>\n","    </tr>\n","    <tr>\n","      <th>181</th>\n","      <td>180</td>\n","      <td>10</td>\n","      <td>180_brilliant_ok_pizza_mediocre</td>\n","      <td>[brilliant, ok, pizza, mediocre, poor, takeawa...</td>\n","      <td>[mediocre pizza, ok pizza, brilliant pizza]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>182 rows × 5 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d30ce895-80d7-4cdd-9a18-ef2961c3dd49')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-d30ce895-80d7-4cdd-9a18-ef2961c3dd49 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-d30ce895-80d7-4cdd-9a18-ef2961c3dd49');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-5073e888-09dc-41a9-98f9-50ae82f90a67\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5073e888-09dc-41a9-98f9-50ae82f90a67')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-5073e888-09dc-41a9-98f9-50ae82f90a67 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":122}],"source":["topic_model.get_topic_info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1emzBXB-lD1j"},"outputs":[],"source":["topic_model.visualize_topics()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0NgdJwKImj-w"},"outputs":[],"source":["topic_model.visualize_hierarchy()"]},{"cell_type":"code","source":[],"metadata":{"id":"NrRngDXwngHr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8JJ8UpM6BnzL"},"source":["## custom approach"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XxSA0pKbBsvD"},"outputs":[],"source":["from transformers import BertTokenizer, BertModel\n","import torch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dRDDcqWpmvrT"},"outputs":[],"source":["# Load a pre-trained BERT model and tokenizer\n","model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n","tokenizer = BertTokenizer.from_pretrained(model_name)\n","model = BertModel.from_pretrained(model_name)\n","\n","# Prepare your input data\n","input_text = keywords_lst[:2]\n","\n","# Tokenize and convert to BERT input format\n","tokenized_input = tokenizer(*input_text, padding=True, truncation=True, return_tensors=\"pt\")\n","\n","# Generate BERT embeddings\n","with torch.no_grad():\n","    outputs = model(**tokenized_input)\n","    embeddings2 = outputs.last_hidden_state"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":283,"status":"ok","timestamp":1693744940270,"user":{"displayName":"Otto Kraus","userId":"09313844023429711923"},"user_tz":-120},"id":"m4Kj6-8UCCQx","outputId":"4656b97d-8e18-4592-ad64-d20b697c17c3"},"outputs":[{"data":{"text/plain":["(torch.Size([6, 6, 384]), torch.Size([6, 12, 384]))"]},"execution_count":89,"metadata":{},"output_type":"execute_result"}],"source":["embeddings.size(), embeddings2.size()"]},{"cell_type":"markdown","metadata":{"id":"dq5Eg1roEb7F"},"source":["### getting cosine similarity between two vectors"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RNuyGblNEbGw"},"outputs":[],"source":["import torch\n","import torch.nn.functional as F"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":325,"status":"ok","timestamp":1693746446953,"user":{"displayName":"Otto Kraus","userId":"09313844023429711923"},"user_tz":-120},"id":"3QYPCHK2DMdC","outputId":"7e34ed0a-11ca-426a-f063-c0abf6da2cee"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cosine Similarity: tensor([[ 0.5551,  0.3613,  0.7036,  ...,  0.3346,  0.4634,  0.3585],\n","        [ 0.6444,  0.2337, -0.2471,  ...,  0.4694,  0.6556,  0.2050],\n","        [ 0.7086,  0.4504, -0.1781,  ...,  0.5310,  0.2568,  0.1821],\n","        [ 0.5031,  0.7434,  0.0050,  ...,  0.5892,  0.6540,  0.2148],\n","        [ 0.1147,  0.7820, -0.4728,  ..., -0.2439,  0.6435,  0.1375],\n","        [ 0.9084,  0.8012,  0.2966,  ...,  0.0740,  0.7396,  0.5129]])\n"]}],"source":["# Define two vectors as PyTorch tensors\n","vector1 = embeddings2[:,:6,:]\n","vector2 = embeddings2[:,6:12,:]\n","\n","# Calculate cosine similarity\n","similarity = F.cosine_similarity(vector1, vector2, dim=0)\n","\n","# Print the cosine similarity\n","print(\"Cosine Similarity:\", similarity)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":280,"status":"ok","timestamp":1693746441172,"user":{"displayName":"Otto Kraus","userId":"09313844023429711923"},"user_tz":-120},"id":"SNfsBEztErE1","outputId":"8ffac737-36a5-41cd-e5f0-0af847367fd1"},"outputs":[{"data":{"text/plain":["(torch.Size([6, 384]), torch.Size([6, 6, 384]), torch.Size([6, 6, 384]))"]},"execution_count":112,"metadata":{},"output_type":"execute_result"}],"source":["similarity.size(), vector1.size(), vector2.size()"]},{"cell_type":"markdown","metadata":{"id":"WgAkzBv8NVwH"},"source":["## approach this with fastai"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rYiKk2dQNZXF"},"outputs":[],"source":["!pip install fastai"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dB4Wcrr7Nb74"},"outputs":[],"source":["import fastai\n","from fastai.text.all import *"]},{"cell_type":"markdown","metadata":{"id":"xlVBMUjzX1xE"},"source":["### initialize tokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ludb8WCINvDT"},"outputs":[],"source":["# this seems to be able to tokenize my input\n","spacy = WordTokenizer()\n","\n","# this somehow doesn't work...\n","tkn = Tokenizer(spacy)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":328},"executionInfo":{"elapsed":6,"status":"error","timestamp":1693856681691,"user":{"displayName":"Otto Kraus","userId":"09313844023429711923"},"user_tz":-120},"id":"8HosJYS6OBer","outputId":"eca3cf36-fb07-4d82-930d-06aab76ab0b8"},"outputs":[{"ename":"TypeError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-43-ec03dbc1c2c3>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# creating tokens from input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtxt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlst\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeywords_lst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtoks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/fastcore/foundation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;31m# %% ../nbs/02_foundation.ipynb 46\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/fastcore/foundation.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, items, use_list, match, *rest)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0muse_list\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/fastcore/basics.py\u001b[0m in \u001b[0;36mlistify\u001b[0;34m(o, use_list, match, *rest)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0;32melif\u001b[0m \u001b[0mis_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-43-ec03dbc1c2c3>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# creating tokens from input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtxt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlst\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeywords_lst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtoks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: sequence item 0: expected str instance, float found"]}],"source":["# creating tokens from input\n","txt = L(\" \".join(lst) for lst in keywords_lst)\n","toks = spacy(txt)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ILWoe4xjIn69"},"outputs":[],"source":["# setup the numericalizer\n","# NOT working atm, need to fix\n","num = Numericalize()\n","num.setup(toks)\n","coll_repr(num.vocab,100)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1693750192003,"user":{"displayName":"Otto Kraus","userId":"09313844023429711923"},"user_tz":-120},"id":"-fVpAjjqYLW9","outputId":"e66a681b-f76f-4f95-b200-0ca9db1ca879"},"outputs":[{"data":{"text/plain":["TensorText([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","            0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","            0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","            0, 0, 0])"]},"execution_count":198,"metadata":{},"output_type":"execute_result"}],"source":["num(txt[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":297,"status":"ok","timestamp":1693750198549,"user":{"displayName":"Otto Kraus","userId":"09313844023429711923"},"user_tz":-120},"id":"J_g82UvzUUN3","outputId":"3faa1ae1-b990-474f-e68e-0acf69f3afa1"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'german cuisine german food authentic german schnitzel cuisine great food'"]},"execution_count":199,"metadata":{},"output_type":"execute_result"}],"source":["txt[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1zfztCiBXqRy"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[],"collapsed_sections":["ZNKPbcPLe-87","rhXcewoxfM3-","wI3nKy2JBhYm","8JJ8UpM6BnzL","WgAkzBv8NVwH"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}